# 软件错误

我们通常认为硬件错误是随机的，而且互相独立，比如某个机器上某块硬盘的失效并不意味着另一块硬盘也即将会失效。硬件的错误之间确实可能有某种微弱
的联系，比如数据中心某个机架里的温度过高就可能是导致几台机器同时故障的原因，但是除此之外几乎不可能在同一时间有大量硬件组件同时失效。

另一类错误是发生于系统内的系统性失效[[8]](README.md#b1_c1_8)。这类错误更难预料，并且因为它们关联到服务中的诸多节点，它们会比互不
关联的硬件错误引起更多的系统失效[[5]](README.md#b1_c1_5)。这样的例子包括：

- 在特定错误输入下会引起所有应用服务器宕机的软件缺陷。比如，2012年6月30日的闰秒导致了许多应用同时挂掉，其原因是Linux内核中的一个
缺陷[[9]](README.md#b1_c1_9)。

- 一个跑飞了的进程耗费了所有共享的资源——CPU时间片、内存、磁盘扩建或者网络带宽。

- 系统依赖的一个服务执行效率降低、无法响应、或者开始返回没有意义的请求响应。

- 连锁的失效，组件中一个小的错误引起了另一个组件中的错误，继而引发更多的错误[[10]](README.md#b1_c1_10)。

引起这些软件错误的缺陷往往会潜伏很久知道被一组特定的条件所激发。在一些场景下我们发现软件会给其所处的运行环境做出预设，而这些预设的条件往往
是真的，但是终究会因为一些原因让这些软件的运行环境偏离预设[[11]](README.md#b1_c1_11)。

应对系统中的系统性失效并没有一个简单的解决方案，但是我们依然可以在很多小事情上做出努力：仔细设想系统的交互；完整的测试；进程隔离；允许进程
崩溃并重启；衡量、检测并分析生产环境中系统的行为。如果一个系统的行为是可预期的（例如，消息队列中进入队列的消息数量等于离开队列的消息数量），
那么系统自身就应该可以在运行中持续自检，并在非预期情况发生时提出报警[[12]](README.md#b1_c1_12)。